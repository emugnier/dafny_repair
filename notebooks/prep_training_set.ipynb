{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing libraries\n",
      "Training and testing datasets already exist for libraries\n",
      "Processing cedar\n",
      "Training and testing datasets already exist for cedar\n",
      "Processing dafnyVMC\n",
      "Training and testing datasets already exist for dafnyVMC\n"
     ]
    }
   ],
   "source": [
    "# load the 3 benchmark datasets\n",
    "datasets = [\"libraries\", \"cedar\", \"dafnyVMC\"]\n",
    "\n",
    "benchmarks = {}\n",
    "for dataset in datasets:\n",
    "    print(\"Processing\", dataset)\n",
    "    if os.path.exists(f\"../results/training_{dataset}.csv\") and os.path.exists(\n",
    "        f\"../results/testing_{dataset}.csv\"\n",
    "    ):\n",
    "        print(f\"Training and testing datasets already exist for {dataset}\")\n",
    "        benchmarks[dataset] = {\n",
    "            \"training\": pd.read_csv(f\"../results/training_{dataset}.csv\"),\n",
    "            \"testing\": pd.read_csv(f\"../results/testing_{dataset}.csv\"),\n",
    "        }\n",
    "    else:\n",
    "        df = pd.read_csv(f\"../results/non_verified_{dataset}.csv\")\n",
    "\n",
    "        # remove duplicates\n",
    "        df.drop_duplicates(subset=[\"Original Method\", \"Assertion\"], inplace=True)\n",
    "\n",
    "        # rewrite the path of \"New Method File\" but keep the same file name\n",
    "        df[\"New Method File\"] = df[\"New Method File\"].apply(\n",
    "            lambda x: os.path.join(\"/exp/dafny_repair/results/\", os.path.basename(x))\n",
    "        )\n",
    "\n",
    "        # split the dataset into training and testing\n",
    "        training = df.sample(frac=0.5)\n",
    "        testing = df.drop(training.index)\n",
    "\n",
    "        # split the dataset using k fold cross validation\n",
    "\n",
    "        # save the datasets\n",
    "        training.to_csv(f\"../results/training_{dataset}.csv\", index=False)\n",
    "        testing.to_csv(f\"../results/testing_{dataset}.csv\", index=False)\n",
    "        benchmarks[dataset] = {\"training\": training, \"testing\": testing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing libraries\n",
      "Training and testing datasets already exist for libraries\n",
      "Processing cedar\n",
      "Training and testing datasets already exist for cedar\n",
      "Processing dafnyVMC\n",
      "Training and testing datasets already exist for dafnyVMC\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "benchmarks = {}\n",
    "for dataset in datasets:\n",
    "    print(\"Processing\", dataset)\n",
    "    all_training_files_exist = all(\n",
    "        os.path.exists(f\"../results/training_{dataset}_k{k}_{i}.csv\")\n",
    "        for i in range(0, k)\n",
    "    )\n",
    "    all_testing_files_exist = all(\n",
    "        os.path.exists(f\"../results/testing_{dataset}_k{k}_{i}.csv\")\n",
    "        for i in range(0, k)\n",
    "    )\n",
    "\n",
    "    if all_testing_files_exist and all_training_files_exist:\n",
    "        print(f\"Training and testing datasets already exist for {dataset}\")\n",
    "        benchmarks[dataset] = {\n",
    "            \"training\": [\n",
    "                pd.read_csv(f\"../results/training_{dataset}_k{k}_{i}.csv\")\n",
    "                for i in range(0, k)\n",
    "            ],\n",
    "            \"testing\": [\n",
    "                pd.read_csv(f\"../results/testing_{dataset}_k{k}_{i}.csv\")\n",
    "                for i in range(0, k)\n",
    "            ],\n",
    "        }\n",
    "        continue\n",
    "    df = pd.read_csv(f\"../results/non_verified_{dataset}.csv\")\n",
    "\n",
    "    # remove duplicates\n",
    "    df.drop_duplicates(subset=[\"Original Method\", \"Assertion\"], inplace=True)\n",
    "\n",
    "    # rewrite the path of \"New Method File\" but keep the same file name\n",
    "    df[\"New Method File\"] = df[\"New Method File\"].apply(\n",
    "        lambda x: os.path.join(\"/exp/dafny_repair/results/\", os.path.basename(x))\n",
    "    )\n",
    "\n",
    "    kf = KFold(n_splits=k)\n",
    "\n",
    "    training_sets = []\n",
    "    testing_sets = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        training = df.iloc[train_index]\n",
    "        testing = df.iloc[test_index]\n",
    "        training_sets.append(training)\n",
    "        testing_sets.append(testing)\n",
    "        # training.to_csv(f\"../results/training_{dataset}_k{k}_id{train_index}.csv\", index=False)\n",
    "        # testing.to_csv(f\"../results/testing_{dataset}_k{k}_id{test_index}.csv\", index=False)\n",
    "    for i, (training, testing) in enumerate(zip(training_sets, testing_sets)):\n",
    "        training.to_csv(f\"../results/training_{dataset}_k{k}_{i}.csv\", index=False)\n",
    "        testing.to_csv(f\"../results/testing_{dataset}_k{k}_{i}.csv\", index=False)\n",
    "    benchmarks[dataset] = {\n",
    "        \"training\": training_sets,\n",
    "        \"testing\": testing_sets,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing libraries\n",
      "Training fold datasets already exist for libraries\n",
      "Processing cedar\n",
      "Training fold datasets already exist for cedar\n",
      "Processing dafnyVMC\n"
     ]
    }
   ],
   "source": [
    "# Pick 6 random examples from the training set\n",
    "for dataset in datasets:\n",
    "    print(\"Processing\", dataset)\n",
    "    training = benchmarks[dataset][\"training\"]\n",
    "    testing = benchmarks[dataset][\"testing\"]\n",
    "\n",
    "    all_training_fold_files_exist = all(\n",
    "        os.path.exists(f\"../results/training_{dataset}_k{k}_sample_{i}.csv\")\n",
    "        for i in range(0, k)\n",
    "    )\n",
    "    if all_training_fold_files_exist:\n",
    "        print(f\"Training fold datasets already exist for {dataset}\")\n",
    "        benchmarks[dataset][\"training\"] = [\n",
    "            pd.read_csv(f\"../results/training_{dataset}_k{k}_sample_{i}.csv\")\n",
    "            for i in range(0, k)\n",
    "        ]\n",
    "        continue\n",
    "\n",
    "    # pick 6 random examples from the training set\n",
    "    for i, training_fold in enumerate(training):\n",
    "        fold = training_fold.sample(n=6)\n",
    "        fold.to_csv(f\"../results/training_{dataset}_k{k}_sample_{i}.csv\", index=False)\n",
    "        benchmarks[dataset][\"training\"][i] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing libraries\n",
      "Training and testing datasets already exist for libraries\n",
      "Processing cedar\n",
      "Training and testing datasets already exist for cedar\n",
      "Processing dafnyVMC\n",
      "Training and testing datasets already exist for dafnyVMC\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "for dataset in datasets:\n",
    "    print(\"Processing\", dataset)\n",
    "    all_training_files_exist = all(\n",
    "        os.path.exists(f\"../results/training_{dataset}_k{k}__{i}.csv\")\n",
    "        for i in range(0, k)\n",
    "    )\n",
    "    all_testing_files_exist = all(\n",
    "        os.path.exists(f\"../results/testing_{dataset}_k{k}__{i}.csv\")\n",
    "        for i in range(0, k)\n",
    "    )\n",
    "\n",
    "    if all_testing_files_exist and all_training_files_exist:\n",
    "        print(f\"Training and testing datasets already exist for {dataset}\")\n",
    "        benchmarks[dataset] = {\n",
    "            \"training\": [\n",
    "                pd.read_csv(f\"../results/training_{dataset}_k{k}__{i}.csv\")\n",
    "                for i in range(0, k)\n",
    "            ],\n",
    "            \"testing\": [\n",
    "                pd.read_csv(f\"../results/training_{dataset}_k{k}__{i}.csv\")\n",
    "                for i in range(0, k)\n",
    "            ],\n",
    "        }\n",
    "        continue\n",
    "    df = pd.read_csv(f\"../results/non_verified_{dataset}.csv\")\n",
    "\n",
    "    # remove duplicates\n",
    "    df.drop_duplicates(subset=[\"Original Method\", \"Assertion\"], inplace=True)\n",
    "\n",
    "    # rewrite the path of \"New Method File\" but keep the same file name\n",
    "    df[\"New Method File\"] = df[\"New Method File\"].apply(\n",
    "        lambda x: os.path.join(\"/exp/dafny_repair/results/\", os.path.basename(x))\n",
    "    )\n",
    "\n",
    "    kf = KFold(n_splits=k)\n",
    "\n",
    "    training_sets = []\n",
    "    testing_sets = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        training = df.iloc[train_index]\n",
    "        testing = df.iloc[test_index]\n",
    "        training_sets.append(training)\n",
    "        testing_sets.append(testing)\n",
    "\n",
    "    for i, (training, testing) in enumerate(zip(training_sets, testing_sets)):\n",
    "        testing.to_csv(f\"../results/training_{dataset}_k{k}__{i}.csv\", index=False)\n",
    "        training.to_csv(f\"../results/testing_{dataset}_k{k}__{i}.csv\", index=False)\n",
    "        print(f\"training length: {len(testing)}\")\n",
    "        print(f\"testing length: {len(training)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = benchmarks[\"libraries\"][\"training\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing libraries\n",
      "Training fold datasets already exist for libraries\n",
      "Processing cedar\n",
      "Training fold datasets already exist for cedar\n",
      "Processing dafnyVMC\n",
      "Training fold datasets already exist for dafnyVMC\n"
     ]
    }
   ],
   "source": [
    "# Pick 6 random examples from the training set\n",
    "for dataset in datasets:\n",
    "    print(\"Processing\", dataset)\n",
    "    training = benchmarks[dataset][\"training\"]\n",
    "    testing = benchmarks[dataset][\"testing\"]\n",
    "\n",
    "    all_training_fold_files_exist = all(\n",
    "        os.path.exists(f\"../results/training_{dataset}_k{k}__sample_{i}.csv\")\n",
    "        for i in range(0, k)\n",
    "    )\n",
    "    if all_training_fold_files_exist:\n",
    "        print(f\"Training fold datasets already exist for {dataset}\")\n",
    "        benchmarks[dataset][\"training\"] = [\n",
    "            pd.read_csv(f\"../results/training_{dataset}_k{k}__sample_{i}.csv\")\n",
    "            for i in range(0, k)\n",
    "        ]\n",
    "        continue\n",
    "\n",
    "    # pick 6 random examples from the training set\n",
    "    for i, training_fold in enumerate(training):\n",
    "        print(f\"training length: {len(training_fold)}\")\n",
    "        fold = training_fold.sample(n=5)\n",
    "        print(\n",
    "            fold.drop(columns=[\"Time Difference\"])\n",
    "            .isin(training_fold.drop(columns=[\"Time Difference\"]))\n",
    "            .all()\n",
    "            .all()\n",
    "        )\n",
    "        fold.to_csv(f\"../results/training_{dataset}_k{k}__sample_{i}.csv\", index=False)\n",
    "        benchmarks[dataset][\"training\"][i] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Original File</th>\n",
       "      <th>Original Method</th>\n",
       "      <th>Original Method Time</th>\n",
       "      <th>Original Method Result</th>\n",
       "      <th>Original Method File</th>\n",
       "      <th>Assertion</th>\n",
       "      <th>Time Difference</th>\n",
       "      <th>New Method File</th>\n",
       "      <th>New Method</th>\n",
       "      <th>New Method Time</th>\n",
       "      <th>New Method Result</th>\n",
       "      <th>New Result File</th>\n",
       "      <th>Assertion Tokens</th>\n",
       "      <th>Method Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  Original File  Original Method  Original Method Time  \\\n",
       "0  False          False            False                 False   \n",
       "1  False          False            False                 False   \n",
       "2  False          False            False                 False   \n",
       "3  False          False            False                 False   \n",
       "4  False          False            False                 False   \n",
       "5  False          False            False                 False   \n",
       "\n",
       "   Original Method Result  Original Method File  Assertion  Time Difference  \\\n",
       "0                    True                 False      False            False   \n",
       "1                    True                 False      False            False   \n",
       "2                    True                 False      False            False   \n",
       "3                    True                 False      False            False   \n",
       "4                    True                 False      False            False   \n",
       "5                    True                 False      False            False   \n",
       "\n",
       "   New Method File  New Method  New Method Time  New Method Result  \\\n",
       "0            False       False            False               True   \n",
       "1            False       False            False               True   \n",
       "2            False       False            False               True   \n",
       "3            False       False            False               True   \n",
       "4            False       False            False               True   \n",
       "5            False       False            False               True   \n",
       "\n",
       "   New Result File  Assertion Tokens  Method Tokens  \n",
       "0            False             False          False  \n",
       "1            False             False          False  \n",
       "2            False             False          False  \n",
       "3            False             False          False  \n",
       "4            False             False          False  \n",
       "5            False             False          False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks[\"libraries\"][\"training\"][0].isin(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {}\n",
    "for dataset in datasets:\n",
    "    if dataset == \"cedar\":\n",
    "        df = pd.read_csv(f\"../results/non_verified_{dataset}.csv\")\n",
    "\n",
    "        # remove duplicates\n",
    "        df.drop_duplicates(subset=[\"Original Method\", \"Assertion\"], inplace=True)\n",
    "\n",
    "        # rewrite the path of \"New Method File\" but keep the same file name\n",
    "        df[\"New Method File\"] = df[\"New Method File\"].apply(\n",
    "            lambda x: os.path.join(\"/exp/dafny_repair/results/\", os.path.basename(x))\n",
    "        )\n",
    "        if dataset == \"cedar\":\n",
    "            df = df.sample(frac=0.5)\n",
    "        content[dataset] = df\n",
    "\n",
    "        if not os.path.exists(f\"../results/placeholder_dataset/\"):\n",
    "            os.makedirs(f\"../results/placeholder_dataset/\")\n",
    "\n",
    "        df.to_csv(f\"../results/placeholder_dataset/{dataset}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
